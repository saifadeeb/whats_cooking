{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "bfd4177ca835e47e0f916d2948619073ddff1678"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadeeb\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_function(func_X_train, func_X_test, func_y_train, func_y_test, parameters, model):\n",
    "    model = model(random_state=RANDOM_SEED)\n",
    "\n",
    "    grid_search = GridSearchCV(model, parameters)\n",
    "\n",
    "    classifier= grid_search.fit(func_X_train,func_y_train)\n",
    "\n",
    "    #score = classifier.score(func_X_test, func_y_test)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(data):\n",
    "    \"\"\"This function removes punctuations, special characters letters, and symbols from a list of words\"\"\"\n",
    "    new_data = []\n",
    "    for recipe in data:\n",
    "        new_recipe = []\n",
    "        for ingredient in recipe:\n",
    "            new_ingredient_list = []\n",
    "            for word in ingredient.split():\n",
    "                word = re.sub('[^a-zA-Z -]+', '', word) # only keeping the letters, spaces, and hyphens\n",
    "                new_ingredient_list.append(wn.morphy(word.lower().strip(\",.!:?;' \")) or word.strip(\",.!:?;' \")) # strip, stem, and append the word\n",
    "            new_recipe.append(' '.join(new_ingredient_list))\n",
    "        new_data.append(new_recipe)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_function(X,y, test_size_percent):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_percent, random_state=RANDOM_SEED)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation(X,y, col_names):\n",
    "    # In[315]:\n",
    "\n",
    "    #ten cross-validation employed here\n",
    "\n",
    "    # specify the k-fold cross-validation design\n",
    "    N_FOLDS = 3\n",
    "\n",
    "    # set up numpy array for storing results\n",
    "    cv_results = np.zeros((N_FOLDS, len(names)))\n",
    "\n",
    "    kf = KFold(n_splits = N_FOLDS, shuffle = False, random_state = RANDOM_SEED)\n",
    "\n",
    "    index_for_fold = 0 #fold count initialized\n",
    "\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        print('\\nFold index:', index_for_fold + 1,\n",
    "             '------------------------------------------')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        print('\\nShape of input data for this fold:',\n",
    "              '\\nData Set: (Observations, Variables)')\n",
    "        print('X_train:', X_train.shape)\n",
    "        print('X_test:',X_test.shape)\n",
    "        print('y_train:', y_train.shape)\n",
    "        print('y_test:',y_test.shape)\n",
    "\n",
    "        index_for_method = 0 #initialize\n",
    "        for name, reg_model in zip(names, regressors):\n",
    "            print('\\nRegression model evaluation for:', name)\n",
    "            print(' Scikit Learn method:', reg_model)\n",
    "            reg_model.fit(X_train, y_train) #fit on the train set for this fold\n",
    "\n",
    "            #evaluate on the test set for this fold\n",
    "            y_test_predict = reg_model.predict(X_test)\n",
    "\n",
    "            fold_method_result = reg_model.score(X_test, y_test)\n",
    "\n",
    "            cv_results[index_for_fold, index_for_method] = fold_method_result\n",
    "            index_for_method += 1\n",
    "\n",
    "        index_for_fold += 1\n",
    "        cv_results_df = pd.DataFrame(cv_results)\n",
    "        cv_results_df.columns = col_names\n",
    "    return cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_info_and_classification_report(X,y,test_size_percent, model):\n",
    "    \"\"\"This function retrieves the training and testing score from a model and calculates the\n",
    "       classification report. The function will output the training score, testing score,\n",
    "       classification report, confusion matrix array, normalized confusion matrix array, and\n",
    "       a dataframe of the normalized confusion matrix. This dataframe can then be used to plot\n",
    "       a confusion matrix error plot.\"\"\"\n",
    "    starttime = time.monotonic()\n",
    "    X_train, X_test, y_train, y_test = train_test_split_function(X,y, test_size_percent)\n",
    "    print(\"\\n--- Fitting Model ---\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\n--- Predicting Cuisines ---\")\n",
    "    y_predict = model.predict(X_test)\n",
    "    print(\"\\n--- Scoring Model ---\")\n",
    "    model_training_score = model.score(X_train,y_train)\n",
    "    \n",
    "    model_testing_score = model.score(X_test,y_test)\n",
    "    print(\"\\n--- Creating Classification Report ---\")\n",
    "    clf_report = classification_report(y_test,\n",
    "                          y_predict,\n",
    "                          target_names = lb_enc.inverse_transform(model.classes_).tolist())\n",
    "    \n",
    "    array = confusion_matrix(y_test, y_predict)\n",
    "    \n",
    "    row_sums = array.sum(axis=1,keepdims=True)\n",
    "    norm_conf_mx = array/row_sums\n",
    "\n",
    "    error_matrix_df = pd.DataFrame(norm_conf_mx, index = [i for i in lb_enc.inverse_transform(model.classes_).tolist()],\n",
    "                  columns = [i for i in lb_enc.inverse_transform(model.classes_).tolist()])\n",
    "    \n",
    "    print(\"\\n\\nThat took \", (time.monotonic()-starttime)/60, \" minutes\")\n",
    "    \n",
    "    return model_training_score, model_testing_score, clf_report, array, norm_conf_mx, error_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_info(model,full_X_train, full_y_train):\n",
    "    \"\"\"Seperate function to run for SVM due to lengthy processing time and conflict when probability = True.\n",
    "       This function will retunr the training and testing score of a predefined model\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split_function(full_X_train, \n",
    "                                                             full_y_train, \n",
    "                                                             test_size_percent = 0.20)\n",
    "    print(\"\\n--- Fitting Model ---\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\n--- Scoring Model ---\")\n",
    "    model_training_score = model.score(X_train,y_train)\n",
    "    model_testing_score = model.score(X_test,y_test)\n",
    "    \n",
    "    return model_training_score,model_testing_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(X,y,test_size_percent, model):\n",
    "    \"\"\"Seperate function to run for SVM due to lengthy processing time and conflict when probability = True.\n",
    "       This function will calculate the classification report, classifcation matrix array, normalized classificaiton\n",
    "       matrix array, and dataframe for the ormalized classificaiton matrix array.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split_function(X,y, test_size_percent)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_predict = model.predict(X_test)\n",
    "    \n",
    "    clf_report = classification_report(y_test,\n",
    "                          y_predict,\n",
    "                          target_names = lb_enc.inverse_transform(model.classes_).tolist())\n",
    "    \n",
    "    array = confusion_matrix(y_test, y_predict)\n",
    "    \n",
    "    row_sums = array.sum(axis=1,keepdims=True)\n",
    "    norm_conf_mx = array/row_sums\n",
    "\n",
    "    error_matrix_df = pd.DataFrame(norm_conf_mx, index = [i for i in lb_enc.inverse_transform(model.classes_).tolist()],\n",
    "                  columns = [i for i in lb_enc.inverse_transform(model.classes_).tolist()])\n",
    "    \n",
    "    return clf_report, array, norm_conf_mx, error_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_submission_file(model, full_X_train, full_y_train, full_X_test ,nameOfcsvfile):\n",
    "    print(\"\\n--- Fitting Model ---\")\n",
    "    starttime = time.monotonic()\n",
    "    model_clf = model.fit(full_X_train,full_y_train)\n",
    "    \n",
    "    print(\"\\n--- Predicting Cuisines ---\")\n",
    "    submission_pred = model_clf.predict(full_X_test)\n",
    "    test_cuisine = lb_enc.inverse_transform(submission_pred)\n",
    "\n",
    "    test_id = [recipe['id'] for recipe in test]\n",
    "\n",
    "    submission_df = pd.DataFrame({'id':test_id, 'cuisine':test_cuisine},columns = ['id','cuisine'])\n",
    "\n",
    "    submission_df.to_csv('{}'.format(nameOfcsvfile), index= False)\n",
    "    print(\"\\n--- Results have been saved ---\")\n",
    "    print(\"\\nThat took \", (time.monotonic()-starttime)/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "b7dbcc60dc522b29ed71a1f6fa057ef2b93a4c74"
   },
   "outputs": [],
   "source": [
    "# #readining in data\n",
    "# train = open_json_file('../input/train.json')\n",
    "# test = open_json_file('../input/test.json')\n",
    "train = json.load(open('train.json'))\n",
    "test = json.load(open('test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "5ab0f0fa620fb8fab8e22132e096835673d7b3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- sample of training data set ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 10259,\n",
       "  'cuisine': 'greek',\n",
       "  'ingredients': ['romaine lettuce',\n",
       "   'black olives',\n",
       "   'grape tomatoes',\n",
       "   'garlic',\n",
       "   'pepper',\n",
       "   'purple onion',\n",
       "   'seasoning',\n",
       "   'garbanzo beans',\n",
       "   'feta cheese crumbles']}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--- sample of training data set ---\")\n",
    "train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "7215aaeee9080f7efd4ef16fc37955e557efe90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- sample of testing data set ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 18009,\n",
       "  'ingredients': ['baking powder',\n",
       "   'eggs',\n",
       "   'all-purpose flour',\n",
       "   'raisins',\n",
       "   'milk',\n",
       "   'white sugar']}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--- sample of testing data set ---\")\n",
    "test[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "7d77185f4b18fcde2d0d720efd8f9b09ad0633c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set size: 39774\n",
      "Testing data set size: 9944\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data set size:\",len(train))\n",
    "print(\"Testing data set size:\",len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b2c324e31a759d5d13fa04e68b17553c073527e8"
   },
   "source": [
    "__Preprocess Steps__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3742e93c3fb64331ec1585c41e340346bd042f1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ingredients for training\n",
    "x_train = list([train[i]['ingredients'] for i in range(len(train))])\n",
    "#labels/cuisines for training\n",
    "y_train_labels = [train[i]['cuisine'] for i in range(len(train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa16941ce789d2c406a09d2926432414fe486258",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ingredients for test data\n",
    "x_test = list([test[i]['ingredients'] for i in range(len(test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9b6ba1866dec862a0f7a0cada165e640f84d905",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pre-process data\n",
    "new_x_train = pre_process_data(x_train)\n",
    "new_x_test = pre_process_data(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e6481285c4f529779f7b36b6d7028a0dd3222eb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare X and y\n",
    "print (\"--- Label Encode the Target Variable ---\")\n",
    "lb_enc = LabelEncoder()\n",
    "y_enc_labels = lb_enc.fit_transform(y_train_labels)\n",
    "print(y_enc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8babc275d20102448388e2a20466c7d6c650b43",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text Data Features\n",
    "def bag_of_words(data):\n",
    "\ttext_data = [' '.join(recipe).lower() for recipe in data] \n",
    "\treturn text_data \n",
    "\n",
    "def concatenated_words(data):\n",
    "\ttext_data = [' '.join(word.replace(\" \",\"_\").lower() for word in recipe) for recipe in data]\n",
    "\treturn text_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25e0d97800bed1e784a5e21ed1df5c0e4fd14791",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"--- Preparing text data ---\")\n",
    "#feature extraction - take #1 \n",
    "train_text = bag_of_words(x_train)\n",
    "submission_text = bag_of_words(x_test)\n",
    "\n",
    "#feature extraction - take #2\n",
    "### Here, we are treating every word as a feature\n",
    "prep_train_text = bag_of_words(new_x_train)\n",
    "prep_submission_text = bag_of_words(new_x_test)\n",
    "\n",
    "#feature extraction - take #3\n",
    "### If an ingredients has multiple words, we will be joining them with an underscore before seperating each ingredient.\n",
    "prep_train_text_underscore = concatenated_words(new_x_train)\n",
    "prep_submission_text_underscore = concatenated_words(new_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d27ef993c31cf444bbbbe2b0f577f5c00fc7a7c"
   },
   "source": [
    "__Feature Engineering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4788205f97a17839b337316d24d21557e39371a5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "tfidf_enc = TfidfVectorizer()\n",
    "\n",
    "def tf_idf_features(text, flag):\n",
    "    \"\"\"Fitting TFIDF vectorizer to training data and transforming everything else\"\"\"\n",
    "    if flag == \"train\":\n",
    "        x = tfidf_enc.fit_transform(text)\n",
    "    else:\n",
    "        x = tfidf_enc.transform(text)\n",
    "    x = x.astype('float16')\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b1815c7344c3a2047642bc8a4de5e115315091a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating features for each feature engineering approach\n",
    "train_text_features = tf_idf_features(train_text, flag=\"train\")\n",
    "submission_text_features = tf_idf_features(submission_text, flag=\"submission\")\n",
    "\n",
    "prep_train_text_features = tf_idf_features(prep_train_text, flag=\"train\")\n",
    "prep_submission_text_features = tf_idf_features(prep_submission_text, flag=\"submission\")\n",
    "\n",
    "prep_train_text_underscore_features = tf_idf_features(prep_train_text_underscore, flag=\"train\")\n",
    "prep_submission_text_underscore_features = tf_idf_features(prep_submission_text_underscore, flag=\"submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "616a154f168f2115df9044778c3ffe912bf28fa7"
   },
   "source": [
    "__Model Creation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55be660bfdf8e79f781a41aeff6a797cf9e8229e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting a benchmark\n",
    "RANDOM_SEED = 1\n",
    "names = ['DecisionTree','RandomForestClassifier','Logistic_Regression', \"SVC\"]\n",
    "\n",
    "#declaring the necessary information for each regression model\n",
    "regressors = [DecisionTreeClassifier(random_state = RANDOM_SEED),\n",
    "    #RandomForestClassifier(n_estimators = 1, random_state = RANDOM_SEED), \n",
    "              RandomForestClassifier(n_estimators = 10, random_state = RANDOM_SEED), \n",
    "              LogisticRegression(random_state = RANDOM_SEED),\n",
    "              SVC(C=10, gamma = 1, decision_function_shape=None, random_state = RANDOM_SEED),\n",
    "              ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d4f90335d01b7f6455cd896e2360248d50ceff0",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "starttime = time.monotonic()\n",
    "\n",
    "print(\"--- Performing 3-fold cross validation ---\\n\")\n",
    "\n",
    "print(\"---------Standard Results---------\")\n",
    "train_text_cv = kfold_cross_validation(train_text_features,\n",
    "                                       y_enc_labels, \n",
    "                                       col_names = [\"DecisionTree\",\n",
    "                                                    \"RandomForest\", \n",
    "                                                    \"LogisticRegression\",\n",
    "                                                    \"SVM\"])\n",
    "\n",
    "print(\"\\n\\n---------Removing Special Characters & Punctuations Results---------\")\n",
    "prep_train_text_cv = kfold_cross_validation(prep_train_text_features,\n",
    "                                            y_enc_labels,\n",
    "                                            col_names = [\"DecisionTree\",\n",
    "                                                         \"RandomForest\",\n",
    "                                                         \"LogisticRegression\",\n",
    "                                                         \"SVM\"])\n",
    "\n",
    "print(\"\\n\\n---------Concatenated Words Results---------\")\n",
    "prep_train_text_underscore_cv = kfold_cross_validation(prep_train_text_underscore_features,\n",
    "                                                       y_enc_labels,\n",
    "                                                      col_names = [\"DecisionTree\",\n",
    "                                                                   'RandomForest',\n",
    "                                                                   'LogisticRegression',\n",
    "                                                                   \"SVM\"])\n",
    "\n",
    "print(\"\\n\\nThat took \", (time.monotonic()-starttime)/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59bcf77b23825537a5283787ece2733fcc5a939c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"--- Standard Scores ---\")\n",
    "print(train_text_cv.mean())\n",
    "print()\n",
    "print(\"--- Removing Special Characters & Punctuations Scores ---\")\n",
    "print(prep_train_text_cv.mean())\n",
    "print()\n",
    "print(\"--- Concatenated Words Scores ---\")\n",
    "print(prep_train_text_underscore_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0044441c542c344ef552db2d4a69177304dd323e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#chose the method of removing special characters and punctuations based on performance\n",
    "baseline_models = pd.DataFrame(prep_train_text_cv.mean(),columns=[\"Avg Accuracy\"])\n",
    "baseline_models = baseline_models.reset_index()\n",
    "baseline_models.columns = [\"Model\",\"Baseline Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0fd204615631f3487f4428e3e2f695a7dcd4a66c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf3df1854e633d360710846e43b8a792f4461e1e"
   },
   "source": [
    "__Hyper-parameter Tuning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b5d23dbd18ff83bd89d3d4f9810b3cb370e312e8"
   },
   "source": [
    "_Random Forest Classifier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20aae0f46a3c91aa912510876a1b28b59d918053",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### RANDOM FOREST CLASSIFIER\n",
    "starttime = time.monotonic()\n",
    "parameters = {'n_estimators':[10,100,300]}\n",
    "X_train, X_test, y_train, y_test = train_test_split_function(prep_train_text_features, \n",
    "                                                             y_enc_labels, \n",
    "                                                             test_size_percent = 0.20)\n",
    "\n",
    "rf_classifier = grid_search_function(X_train, X_test, y_train, y_test, \n",
    "                                     parameters, \n",
    "                                     model = RandomForestClassifier)\n",
    "\n",
    "print(\"\\n\\nThat took \", (time.monotonic()-starttime)/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb02ea929181d6fc8e72f9e72bb05f8a254f047c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ee4627459393f6a08cd9a79444726f4de7176eb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_score_rf,testing_score_rf,rf_classification_report, rf_array, rf_norm_conf_mx, rf_error_matrix_df = training_info_and_classification_report(prep_train_text_features,\n",
    "                                                                                                     y_enc_labels,\n",
    "                                                                                                     test_size_percent = 0.20,\n",
    "                                                                                                     model = rf_classifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cf942ba6d4bd3790e155f020e2e0dd20c2611d7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"           Random Forest Classification Report           \")\n",
    "print(rf_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ca83ad911d7cc52b85408acf659966fa6ae8b12",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,15))\n",
    "sns.heatmap(rf_error_matrix_df, annot=False, fmt='g',cmap=\"Greens\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title(\"Confusion Matrix Error Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "576d19e32200b226111be3f4013b057a46e57c43"
   },
   "source": [
    "_Logistic Regression_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16e864d706f5a69caba148d41ee1a2b7f023b8e7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starttime = time.monotonic()\n",
    "parameters = {'C':[1,5,10,100,1000]}\n",
    "X_train, X_test, y_train, y_test = train_test_split_function(prep_train_text_features, \n",
    "                                                             y_enc_labels, \n",
    "                                                             test_size_percent = 0.20)\n",
    "\n",
    "logreg_classifier = grid_search_function(X_train, X_test, y_train, y_test, parameters, model = LogisticRegression)\n",
    "print(\"\\n\\nThat took \", (time.monotonic()-starttime)/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3cb341ebc131b2e4e77c30406ec7a4a006396e7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bef8740b3e7747275e464fa8a402d9a354330fe7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_score_lgr,testing_score_lgr,lgr_classification_report, lgr_array, lgr_norm_conf_mx, lgr_error_matrix_df = training_info_and_classification_report(prep_train_text_features,\n",
    "                                                                                                     y_enc_labels,\n",
    "                                                                                                     test_size_percent = 0.20,\n",
    "                                                                                                     model = logreg_classifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82500106a9a3c933f27558dd1294a01b7bd09804",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"           Logistic Regression Classification Report           \")\n",
    "print(lgr_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a01946e49f71ff7069b25aac617a1179a7a9f5e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,15))\n",
    "sns.heatmap(rf_error_matrix_df, annot=False, fmt='g',cmap=\"Greens\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title(\"Confusion Matrix Error Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ac655a6a7bc71cb04cf039d0f79a2066e1470e8"
   },
   "source": [
    "_SVM_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39e9ce32deddfdcd23a72bf36858a74a9974e941",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Took ~8 Hours to run this GridSearch\n",
    "#starttime = time.monotonic()\n",
    "#\n",
    "#parameters = {'C':(1,10,100,300), 'decision_function_shape':[None], 'gamma': (0.01,1,2,3,'auto'), 'kernel':('rbf','poly','linear') }\n",
    "#\n",
    "#X_train, X_test, y_train, y_test = train_test_split_function(prep_train_text_features, \n",
    "#                                                             y_enc_labels, \n",
    "#                                                             test_size_percent = 0.20)\n",
    "#\n",
    "#all_svm_classifier = grid_search_function(X_train, X_test, y_train, y_test, parameters, model = SVC)\n",
    "#\n",
    "#print(\"\\n\\nThat took \", (time.monotonic()-starttime)/60, \" minutes\")\n",
    "#\n",
    "#all_svm_classifier.best_estimator_\n",
    "\n",
    "##winning parameters: (C=1, decision_function_shape = None, gamma= 1, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46e0a1057d09f7727fad21bbe9afb651d20895c0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_clf = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "svm_ovr = OneVsRestClassifier(svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "324c909a4776eca9df2130541fa6d34fad536692",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_score_svm, testing_score_svm = get_training_info(svm_ovr,prep_train_text_features,y_enc_labels)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b5b4e1823249ccd1f91cb131c85737a78e61579",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need 'probability = True' for OneVsRestClassifier VotingClassifier\n",
    "p_svm_clf = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
    "  max_iter=-1, probability=True, random_state=1, shrinking=True,\n",
    "  tol=0.001, verbose=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aae1102cf36a01d1d1b0ab2dec944f3e3f13027f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#svm_ovr = OneVsRestClassifier(all_svm_classifier.best_estimator_)\n",
    "svm_ovr_clf = OneVsRestClassifier(p_svm_clf)\n",
    "svm_classification_report, svm_array, svm_norm_conf_mx, svm_error_matrix_df = get_classification_report(prep_train_text_features,\n",
    "                                                                                                     y_enc_labels,\n",
    "                                                                                                     test_size_percent = 0.20,\n",
    "                                                                                                     model = svm_ovr_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61d52e5ab1cac66fb3f6942cc93db9ad5dcc4e63",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"           SVM Classification Report           \")\n",
    "print(svm_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "869c167ce2677784b106f65d2ca2f6d0f74948af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,15))\n",
    "sns.heatmap(svm_error_matrix_df, annot=False, fmt='g',cmap=\"Greens\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title(\"Confusion Matrix Error Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2db3adffd05402f08cb0bac1564e2bffd7d2f5f5"
   },
   "source": [
    "*Best Results for each model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd91e4177eacca4c237b139f8838c71c8886472e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf = rf_classifier.best_estimator_\n",
    "lgr_clf = logreg_classifier.best_estimator_\n",
    "#svm_clf = all_svm_classifier.best_estimator_\n",
    "\n",
    "print(rf_clf,\"\\n\")\n",
    "print(lgr_clf,\"\\n\")\n",
    "print(svm_clf,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21f15c5740c47680d3161772d27d46b81eeb8d47",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starttime = time.monotonic()\n",
    "#print(\"Getting best model results for Random Forest classifier\")\n",
    "#training_score_rf,testing_score_rf=get_training_info(rf_clf,prep_train_text_features,y_enc_labels)\n",
    "#print(\"\\nThat took \", (time.monotonic()-starttime)/60, \" minutes\\n\")\n",
    "#\n",
    "#starttime = time.monotonic()\n",
    "#print(\"Getting best model results for Logistic Regression\")\n",
    "#training_score_lgr,testing_score_lgr=get_training_info(lgr_clf,prep_train_text_features,y_enc_labels)\n",
    "#print(\"\\nThat took \", (time.monotonic()-starttime)/60, \" minutes\\n\")\n",
    "#\n",
    "#starttime = time.monotonic()\n",
    "#print(\"Getting best model results for SVM\")\n",
    "###Already retrieved##\n",
    "##svm_ovr_clf = OneVsRestClassifier(svm_clf)\n",
    "##training_score_svm,testing_score_svm=get_training_info(svm_ovr_clf,prep_train_text_features,y_enc_labels)\n",
    "#print(\"\\nThat took \", (time.monotonic()-starttime)/60, \" minutes\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19ed2f971d2d3cb8c585bf65056fa1bc42142475",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"Random Forest Classifier\",\n",
    "    \"Logistic Regression\",\n",
    "    \"SVM\",\n",
    "    \"VotingClassifier\"]\n",
    "\n",
    "\n",
    "best_model_testing_score = [\n",
    "    testing_score_rf,\n",
    "    testing_score_lgr,\n",
    "    testing_score_svm,\n",
    "    \"-\"\n",
    "                   ]\n",
    "\n",
    "best_model_training_score = [\n",
    "    training_score_rf,\n",
    "    training_score_lgr,\n",
    "    training_score_svm,\n",
    "    \"-\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "055087581761807ae9f9282d67f290ff514f95f4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_to_submission_file(model, full_X_train, full_y_train, full_X_test ,nameOfcsvfile):\n",
    "    print(\"\\n--- Fitting Model ---\")\n",
    "    starttime = time.monotonic()\n",
    "    model_clf = model.fit(full_X_train,full_y_train)\n",
    "    \n",
    "    print(\"\\n--- Predicting Cuisines ---\")\n",
    "    submission_pred = model_clf.predict(full_X_test)\n",
    "    test_cuisine = lb_enc.inverse_transform(submission_pred)\n",
    "\n",
    "    test_id = [recipe['id'] for recipe in test]\n",
    "\n",
    "    submission_df = pd.DataFrame({'id':test_id, 'cuisine':test_cuisine},columns = ['id','cuisine'])\n",
    "\n",
    "    submission_df.to_csv('{}'.format(nameOfcsvfile), index= False)\n",
    "    print(\"\\n--- Results have been saved ---\")\n",
    "    print(\"\\nThat took \", (time.monotonic()-starttime)/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6230466fd5ee0d894269421b2f247dd8cf4acb44",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_to_submission_file(model=rf_clf,\n",
    "#                         full_X_train=prep_train_text_features,\n",
    "#                         full_y_train=y_enc_labels,\n",
    "#                         full_X_test=prep_submission_text_features,\n",
    "#                         nameOfcsvfile=\"randomforest_model.csv\")\n",
    "##0.75663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "990f19288f712c0e390c30815f71d5f1749dd5c6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_to_submission_file(model=lgr_clf,\n",
    "#                         full_X_train=prep_train_text_features,\n",
    "#                         full_y_train=y_enc_labels,\n",
    "#                         full_X_test=prep_submission_text_features,\n",
    "#                         nameOfcsvfile=\"logistic_regression_model.csv\")\n",
    "##0.78751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "966898d9cacc0529e713841501910d0226b0e7cf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ovr_svm = OneVsRestClassifier(svm_clf, n_jobs = 4)\n",
    "\n",
    "model_to_submission_file(model=ovr_svm,\n",
    "                         full_X_train=prep_train_text_features,\n",
    "                         full_y_train=y_enc_labels,\n",
    "                         full_X_test=prep_submission_text_features,\n",
    "                         nameOfcsvfile=\"svm_model.csv\")\n",
    "#0.81999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87586efdc7d92d7ef5c0708c7261a77fe8074492",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ovr_svm = OneVsRestClassifier(p_svm_clf, n_jobs = 4)\n",
    "#vt_clf = VotingClassifier(estimators=[('rf',rf_clf), \n",
    "#                                      ('log_reg',lgr_clf),\n",
    "#                                      ('SVM+ovr', ovr_svm)],\n",
    "#                                      voting = 'soft',\n",
    "#                                      weights = [1,2,4])\n",
    "#vt_clf.fit(prep_train_text_features,y_enc_labels)\n",
    "#\n",
    "#submission_pred = vt_clf.predict(prep_submission_text_features)\n",
    "#test_cuisine = lb_enc.inverse_transform(submission_pred)\n",
    "#\n",
    "#test_id = [recipe['id'] for recipe in test]\n",
    "#\n",
    "#submission_df = pd.DataFrame({'id':test_id, 'cuisine':test_cuisine},columns = ['id','cuisine'])\n",
    "#submission_df.to_csv('votingclassifier.csv', index= False)\n",
    "##0.81989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6fa10ee756048a9bc880d6ef8764eec75a7b2f8c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission score\n",
    "model_testing_score = [0.75663, 0.78751, 0.81999, 0.81989]\n",
    "\n",
    "pd.DataFrame({\"Model\":model_names,\n",
    "              \"Training Score\":best_model_training_score,\n",
    "              \"Testing Score\": best_model_testing_score,\n",
    "              \"Submission Score\": model_testing_score},\n",
    "             columns=[\"Model\",\"Training Score\", \"Testing Score\", \"Submission Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb079d17636aa1e9b655acb64dbbc510b4d0786e",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
